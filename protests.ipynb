{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, AdamW, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn import feature_extraction, preprocessing, naive_bayes\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to data\n",
    "path = \"protest_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into lists\n",
    "data = ([], [])\n",
    "with open(path, newline='') as csvfile:\n",
    "    d = csv.DictReader(csvfile)\n",
    "    for row in d:\n",
    "        #print(row)\n",
    "        data[0].append(row[\"text\"])\n",
    "        data[1].append(row[\"2XisjFSSIK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing, tokenization, and lemmatization for baseline:\n",
    "stopwords = nltk.corpus.stopwords.words(\"german\")\n",
    "sentence_list = data[0]\n",
    "cleaned_sentence_list = []\n",
    "for sentence in sentence_list:\n",
    "    sentence = re.sub('@[a-zA-Z_]*', '@tag', sentence)\n",
    "    sentence = re.sub('[&+#]', '', sentence)\n",
    "    sentence = re.sub('(https://|www.)[a-zA-Z./0-9!?_=-]*', 'url', sentence)\n",
    "    sentence = re.sub('(\\((dpa|ots)\\)|(dpa|ots|AP))', '', sentence)\n",
    "    word_list = sentence.split()\n",
    "    word_list = [word for word in word_list if word not in stopwords]\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    stemmed_list = [stemmer.stem(word) for word in word_list]\n",
    "    lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    lemmatized_list = [lemmatizer.lemmatize(word) for word in stemmed_list]\n",
    "    sen = \" \".join(lemmatized_list)\n",
    "    cleaned_sentence_list.append(sen)\n",
    "\n",
    "# split into train and test set (no validation data necessary) for baseline    \n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(cleaned_sentence_list, data[1], test_size=0.2, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf for baseline:\n",
    "tfidf_vectorizer = feature_extraction.text.TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_base)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_base)\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_test_tfidf = X_test_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes baseline:\n",
    "classifier = naive_bayes.MultinomialNB()\n",
    "classifier.fit(X_train_tfidf, y_train_base)\n",
    "pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test_base, pred)\n",
    "precision = precision_score(y_test_base, pred, pos_label=\"1\")\n",
    "recall = recall_score(y_test_base, pred, pos_label=\"1\")\n",
    "f1 = f1_score(y_test_base, pred, pos_label=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, test and val set\n",
    "X = data[0]\n",
    "y = data[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=35)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-german-cased')\n",
    "# alternatively, bert-base-multilingual-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and truncate all sentences to 150 tokens\n",
    "\n",
    "X_train_t = tokenizer(X_train, padding=True, truncation=True, max_length=150, return_tensors=\"pt\")\n",
    "X_val_t = tokenizer(X_val, padding=True, truncation=True, max_length=150, return_tensors=\"pt\")\n",
    "X_test_t = tokenizer(X_test, padding=True, truncation=True, max_length=150, return_tensors=\"pt\")\n",
    "y_train = list(map(int, y_train))\n",
    "y_val = list(map(int, y_val))\n",
    "y_test = list(map(int, y_test))\n",
    "y_train_t = torch.tensor(y_train)\n",
    "y_val_t = torch.tensor(y_val)\n",
    "y_test_t = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use torch Dataloader for sampling and batching\n",
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(X_train_t[\"input_ids\"], X_train_t[\"attention_mask\"], y_train_t)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(X_val_t[\"input_ids\"], X_val_t[\"attention_mask\"], y_val_t)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(X_test_t[\"input_ids\"], X_test_t[\"attention_mask\"], y_test_t)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with Huggingface's BertForSequenceClassification \n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-german-cased', return_dict=True)\n",
    "# alternatively, bert-base-multilingual-cased\n",
    "\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "for e in range(3):\n",
    "    for batch in train_dataloader:\n",
    "        optim.zero_grad()\n",
    "        inputs, mask, labels = batch\n",
    "        outputs = model(inputs, attention_mask=mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(outputs.loss)\n",
    "\n",
    "    print(\"e:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation using Huggingface's BertForSequenceClassification\n",
    "\n",
    "model.eval()\n",
    "\n",
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1_scores = []\n",
    "for batch in val_dataloader:\n",
    "    inputs, mask, labels = batch\n",
    "    outputs = model(inputs, attention_mask=mask, labels=labels)\n",
    "    preds = torch.argmax(outputs.logits, dim = 1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    accuracies.append(accuracy)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    f1_scores.append(f1)\n",
    "    print(accuracy, recall, precision, f1)\n",
    "\n",
    "tot_acc = np.mean(np.array(accuracies))\n",
    "tot_rec = np.mean(np.array(recalls))\n",
    "tot_pre = np.mean(np.array(precisions))\n",
    "tot_f1 = np.mean(np.array(f1_scores))\n",
    "print(tot_acc, tot_rec, tot_pre, tot_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own model with three options regarding output layers:\n",
    "\n",
    "class ProtestClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_layer, dropout=0.5, freeze=True):\n",
    "        super(ProtestClassifier, self).__init__()\n",
    "        \n",
    "        self.bert = BertModel.from_pretrained('bert-base-german-cased')\n",
    "        # alternatively, bert-base-multilingual-cased\n",
    "        self.output_layer = output_layer\n",
    "        \n",
    "        if self.output_layer == \"linear\":\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_size),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, 1)) \n",
    "        if self.output_layer == \"LSTM\":\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.LSTM(input_size, hidden_size, batch_first = True))#,\n",
    "        if self.output_layer == \"CNN\":\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Conv1d(150, 150, 3, padding=True))\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(hidden_size*150, 1)\n",
    "        self.lin3 = nn.Linear(383*150, 1)\n",
    "        self.max = nn.MaxPool1d(3, stride=2)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "        \n",
    "        # freeze all, some, or none of the bert layers\n",
    "        if freeze == True:\n",
    "            for p in self.bert.parameters():\n",
    "                p.requires_grad = False\n",
    "        elif freeze == False:\n",
    "            for p in self.bert.parameters():\n",
    "                p.requires_grad = True\n",
    "        else:\n",
    "            modules = [self.bert.embeddings, *self.bert.encoder.layer[:freeze]]\n",
    "            for module in modules:\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = False\n",
    "    \n",
    "    def forward(self, input_ids, mask):\n",
    "        last_h, cls = self.bert(input_ids=input_ids, attention_mask = mask)\n",
    "        if self.output_layer == \"LSTM\":\n",
    "            c, (hn, cn) = self.classifier(last_h)\n",
    "            c = torch.flatten(c, start_dim = 1)\n",
    "            c = self.relu(c)\n",
    "            c = self.lin2(c)\n",
    "            c = torch.flatten(c)\n",
    "        elif self.output_layer == \"CNN\":\n",
    "            c = self.classifier(last_h)\n",
    "            c = self.relu(c)\n",
    "            c = self.max(c)\n",
    "            c = torch.flatten(c, start_dim = 1)\n",
    "            c = self.lin3(c)\n",
    "            c = torch.flatten(c)  \n",
    "        elif self.output_layer == \"linear\":\n",
    "            c = self.classifier(cls)\n",
    "            c = torch.flatten(c)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross-validation, to verify that results are representative across folds\n",
    "# using own models\n",
    "\n",
    "# set hyperparameters\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "input_size = 768\n",
    "hidden_size = 50\n",
    "output_layer = \"linear\"\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "# fold loop\n",
    "for n, (train_index, test_index) in enumerate(kf.split(X_train_t[\"input_ids\"])):\n",
    "    tot_accuracies = []\n",
    "    tot_recalls = []\n",
    "    tot_precisions = []\n",
    "    tot_f1_scores = []\n",
    "\n",
    "    X_train_id, X_test_id = X_train_t[\"input_ids\"][train_index], X_train_t[\"input_ids\"][test_index]\n",
    "    X_train_am, X_test_am = X_train_t[\"attention_mask\"][train_index], X_train_t[\"attention_mask\"][test_index]\n",
    "    y_train, y_test = y_train_t[train_index], y_train_t[test_index]\n",
    "\n",
    "\n",
    "    train_data = TensorDataset(X_train_id, X_train_am, y_train)\n",
    "    test_data = TensorDataset(X_test_id, X_test_am, y_test)\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "    \n",
    "    model_b = ProtestClassifier(input_size, hidden_size, output_layer, 0.5).to(device)\n",
    "    optim_b = torch.optim.Adam(model_b.parameters(), lr=0.00001)\n",
    "    model_b.train()\n",
    "    # training loop\n",
    "    for e in range(2):\n",
    "        for batch in train_dataloader:\n",
    "            optim_b.zero_grad()\n",
    "            inputs, mask, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            mask = mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model_b(inputs, mask)\n",
    "            labels = labels.float()\n",
    "            loss = loss_fn(pred, labels)\n",
    "            loss.backward()\n",
    "            optim_b.step()\n",
    "\n",
    "    # evaluation loop\n",
    "    model_b.eval()\n",
    "    accuracies = []\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    f1_scores = []\n",
    "    for batch in test_dataloader:\n",
    "        inputs, mask, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model_b(inputs, mask)\n",
    "        prob = torch.sigmoid(out)\n",
    "        pred = prob > 0.5\n",
    "        pred = pred.cpu()\n",
    "        accuracy = accuracy_score(labels, pred)\n",
    "        recall = recall_score(labels, pred)\n",
    "        precision = precision_score(labels, pred)\n",
    "        f1 = f1_score(labels, pred)\n",
    "        accuracies.append(accuracy)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        f1_scores.append(f1)\n",
    "    # calculate average scores per fold\n",
    "    tot_acc = np.mean(np.array(accuracies))\n",
    "    tot_rec = np.mean(np.array(recalls))\n",
    "    tot_pre = np.mean(np.array(precisions))\n",
    "    tot_f1 = np.mean(np.array(f1_scores))\n",
    "    print(\"fold\", n, \":\", tot_acc, tot_rec, tot_pre, tot_f1)\n",
    "    tot_accuracies.append(tot_acc)\n",
    "    tot_recalls.append(tot_rec)\n",
    "    tot_precisions.append(tot_pre)\n",
    "    tot_f1_scores.append(tot_f1)\n",
    "\n",
    "# calculate overall average scores\n",
    "print(\"averages scores across folds:\")\n",
    "print(np.mean(np.array(tot_accuracies)))\n",
    "print(np.mean(np.array(tot_recalls)))\n",
    "print(np.mean(np.array(tot_precisions)))\n",
    "print(np.mean(np.array(tot_f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for tensor board\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=0).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with own models\n",
    "\n",
    "device = \"cuda:1\"\n",
    "\n",
    "\n",
    "input_size = 768\n",
    "hidden_size = 100\n",
    "output_layer = \"CNN\"\n",
    "freeze = False\n",
    "lr = 0.00001  \n",
    "epochs = 3\n",
    "dropout = 0.2\n",
    "bert = \"German Bert\"\n",
    "model_b = ProtestClassifier(input_size, hidden_size, output_layer, dropout, freeze).to(device)\n",
    "optim_b = torch.optim.Adam(model_b.parameters(), lr = lr)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model_b.train()\n",
    "comment = f' bert = {bert} output_layer = {output_layer} freeze = {freeze} hidden_size = {hidden_size} lr = {lr} epochs = {epochs}'\n",
    "tb = SummaryWriter(comment=comment)\n",
    "\n",
    "# make image and graph for tensor board:\n",
    "input_data, mask, labels = next(iter(train_dataloader))\n",
    "input_data = input_data.to(device)\n",
    "mask = mask.to(device)\n",
    "labels = labels.to(device)\n",
    "grid = torchvision.utils.make_grid(input_data)\n",
    "tb.add_image(\"input_data\", grid)\n",
    "tb.add_graph(model_b, (input_data, mask))\n",
    "\n",
    "# training loop\n",
    "for e in range(epochs):\n",
    "    tot_loss = 0\n",
    "    tot_correct = 0\n",
    "    for batch in train_dataloader:\n",
    "        optim_b.zero_grad()\n",
    "        inputs, mask, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        mask = mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model_b(inputs, mask)\n",
    "        labels = labels.float()\n",
    "        loss = loss_fn(pred, labels)\n",
    "        \n",
    "        tot_loss += loss.item()\n",
    "        tot_correct+= get_num_correct(pred, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optim_b.step()\n",
    "        print(loss)\n",
    "\n",
    "    tb.add_scalar(\"Loss\", tot_loss, e)\n",
    "    tb.add_scalar(\"training correct\", tot_correct, e)\n",
    "    tb.add_scalar(\"training accuracy\", tot_correct/ len(train_data), e)\n",
    "    \n",
    "    for name, weight in model_b.named_parameters():\n",
    "        tb.add_histogram(name, weight, e)\n",
    "    \n",
    "    print(\"epoch:\", e, \"total_correct:\", tot_correct, \"loss:\",tot_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation with own models\n",
    "\n",
    "model_b.eval()\n",
    "\n",
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1_scores = []\n",
    "for batch in val_dataloader:\n",
    "    inputs, mask, labels = batch\n",
    "    inputs = inputs.to(device)\n",
    "    mask = mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model_b(inputs, mask)\n",
    "    prob = torch.sigmoid(out)\n",
    "    pred = prob > 0.5\n",
    "    pred = pred.cpu()\n",
    "    accuracy = accuracy_score(labels, pred)\n",
    "    recall = recall_score(labels, pred)\n",
    "    precision = precision_score(labels, pred)\n",
    "    f1 = f1_score(labels, pred)\n",
    "    accuracies.append(accuracy)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    f1_scores.append(f1)\n",
    "    print(accuracy, recall, precision, f1)\n",
    "    \n",
    "tot_acc = np.mean(np.array(accuracies))\n",
    "tot_rec = np.mean(np.array(recalls))\n",
    "tot_pre = np.mean(np.array(precisions))\n",
    "tot_f1 = np.mean(np.array(f1_scores))\n",
    "print(tot_acc, tot_rec, tot_pre, tot_f1)\n",
    "\n",
    "# add hyperparamters and results to tensor board\n",
    "tb.add_hparams(\n",
    "            {\"output_layer\": output_layer, \"freeze\": freeze, \"hidden_size\": hidden_size, \"lr\": lr, \"epochs\": epochs},\n",
    "            {\n",
    "                \"accuracy\": tot_acc,\n",
    "                \"recall\": tot_rec,\n",
    "                \"precision\": tot_pre,\n",
    "                \"f1-score\": tot_f1,\n",
    "                \"loss\": tot_loss,\n",
    "            },\n",
    "        )\n",
    "\n",
    "tb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
